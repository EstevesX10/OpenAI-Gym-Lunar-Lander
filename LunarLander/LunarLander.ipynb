{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b017f3e-1a96-461f-a4e7-592c33e99de8",
   "metadata": {},
   "source": [
    "---\n",
    "<div align = \"center\">\n",
    "\n",
    "# Lunar Lander\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "<div align=\"center\">\n",
    "\n",
    "## Project Overview\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "This project explores the impact of customizing an ``OpenAI Gym Environment`` on **reinforcement learning (RL) performance**. We modified an existing Gym environment - Lunar Lander - in order to train an RL agent using the Stable Baselines library, and later compare results between the **customized and original environments**.\n",
    "\n",
    "The process involves:\n",
    "\n",
    "- **Environment Customization**: **Implement changes** such as altered rewards or added challenges to the Environment.\n",
    "- **Agent Training**: Train an RL agent with **algorithms like PPO** and further **tune their hyperparameters** to ensure optimal performance.\n",
    "- **Evaluation**: **Compare agent performance** in both environments to analyze the effect of the customizations.\n",
    "\n",
    "This project aims to analyse **how does the environment design influence the outcomes of a Reinforcement Learning Algorithm**.\n",
    "\n",
    "---\n",
    "## Dependencies\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb5727-86af-42b7-8e15-5c0cf3dbd367",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87299ec2-3baf-448d-8fe4-767d6bfe5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d04ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from stable_baselines3 import (PPO)\n",
    "from stable_baselines3.common.env_util import (make_vec_env)\n",
    "from stable_baselines3.common.vec_env import (SubprocVecEnv)\n",
    "from stable_baselines3.common.callbacks import (CheckpointCallback, EveryNTimesteps)\n",
    "\n",
    "from Configuration import (CONFIG, PATHS_CONFIG,\n",
    "                            PPO_SETTINGS_1, DQN_SETTING_1)\n",
    "from Environment import (MyLunarLander)\n",
    "from LunarLanderManager import (LunarLanderManager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc30c48-952f-4872-bcfb-b0ce2a916595",
   "metadata": {},
   "source": [
    "---\n",
    "## Original Environment\n",
    "---\n",
    "\n",
    "Initially let's create the Original Lunar Lander Environment and define a Reinforcement Learning Model to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ea3ce-1dbd-49e6-aacf-06e1b86cebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the Original Environment\n",
    "originalEnv = 'LunarLander'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4588c8-bfd0-49e7-a3bb-9196598e5400",
   "metadata": {},
   "source": [
    "---\n",
    "### PPO (Setting 1)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa799099-423e-4822-b2fd-d5a448f94203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a instance of the Lunar Lander Manager\n",
    "ppoSetup1 = LunarLanderManager(environmentName=originalEnv, algorithm='PPO', settingsNumber=1, algorithmSettings=PPO_SETTINGS_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f519087-6df2-43f8-88f2-f3eec7b2387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the Environment is working\n",
    "ppoSetup1.testRandomAction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26118f9c-9542-4c37-9ddb-3e74c8788ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "model = ppoSetup1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e2db0-a1b7-4aec-954b-41e19a638b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model over 1 Episode \n",
    "ppoSetup1.test(model=model, numEpisodes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b170b3-4d0b-4856-9912-d6e08148fd98",
   "metadata": {},
   "source": [
    "---\n",
    "### DQN (Setting 1)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d01ad-ffcb-4f58-8636-516d50a469b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a instance of the Lunar Lander Manager\n",
    "dqnSetup1 = LunarLanderManager(environmentName=originalEnv, algorithm='DQN', settingsNumber=1, algorithmSettings=DQN_SETTING_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed7885c-f7c6-43a4-be1e-a9e72884b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the Environment is working\n",
    "dqnSetup1.testRandomAction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e26b49-a8ac-4cd0-bd98-90ae200c2ea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "model = dqnSetup1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ec6f8-a3e4-4d42-91f5-2ff206ec44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model over 1 Episode \n",
    "dqnSetup1.test(model=model, numEpisodes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928fbb05-523f-41e7-b83a-700f526e5875",
   "metadata": {},
   "source": [
    "---\n",
    "## Custom Environment\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a15c0c-984b-448a-b145-6bb9ffa388ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Register the Custom Environment\n",
    "gym.register(\n",
    "    id=\"MyLunarLander\",\n",
    "    entry_point=MyLunarLander,\n",
    ")\n",
    "\n",
    "# Define the custom environment\n",
    "customEnv = 'MyLunarLander'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2a2430-c4ff-4521-9b8c-b3999a574094",
   "metadata": {},
   "source": [
    "---\n",
    "### PPO (Setting 1)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788c24b1-6eda-439a-aee3-f3f0bf13804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a instance of the Lunar Lander Manager\n",
    "ppoSetup1 = LunarLanderManager(environmentName=customEnv, algorithm='PPO', settingsNumber=1, algorithmSettings=PPO_SETTINGS_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc84c30-2ac6-4485-9f4e-972431194bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the Environment is working\n",
    "ppoSetup1.testRandomAction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092acf8-5a68-4d68-b9a1-f446399e1f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "model = ppoSetup1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c5b39-d569-4438-a60b-02cfa501a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model over 1 Episode \n",
    "ppoSetup1.test(model=model, numEpisodes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca306cf0-4d21-4594-8f57-71682726f8f7",
   "metadata": {},
   "source": [
    "---\n",
    "### DQN (Setting 1)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d8d5a-a9f5-413c-a9ef-f3799b381ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a instance of the Lunar Lander Manager\n",
    "dqnSetup1 = LunarLanderManager(environmentName=customEnv, algorithm='DQN', settingsNumber=1, algorithmSettings=DQN_SETTING_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e918b8c9-1871-47e3-9e35-b1d404103244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the Environment is working\n",
    "dqnSetup1.testRandomAction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5089d139-bdf5-4873-bfdf-bc4acfa72b50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "model = dqnSetup1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5a98b-7736-41b5-8f76-21482a34e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model over 1 Episode \n",
    "dqnSetup1.test(model=model, numEpisodes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fbf8fa-6b62-4e58-9e9e-de098a3672a1",
   "metadata": {},
   "source": [
    "---\n",
    "### REMENDOS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ebdb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the DQN Model after Trainning\n",
    "mean_reward, std_reward = evaluate_policy(model_DQN, env, n_eval_episodes=5, render=True)\n",
    "print(\"-> DQN\")\n",
    "print(\"Mean Reward: {}\\nStandard Deviation: {}\".format(mean_reward, std_reward))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29afe426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Trained Models\n",
    "model_DQN.save(\"./Models/DQN_Lunar\")\n",
    "model_ACER.save(\"./Models/ACER_Lunar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba49c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the Models so that we can later load them\n",
    "del model_DQN\n",
    "del model_ACER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90769c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Previouly Saved Models\n",
    "model_DQN = DQN.load(\"./Models/DQN_Lunar.zip\")\n",
    "model_ACER = ACER.load(\"./Models/ACER_Lunar.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
